{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment5_softcomputing_mit2020017",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3fNRgdNyqk_"
      },
      "source": [
        "#DATA COLLECTION - train and test data is collected from my mail box to get the feel of how actually the algorithms work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0xzoQ6vJRG-"
      },
      "source": [
        "##train data is collected from my mail box, here zero index indicates normal messsage and one indicates spam mail "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8jAWSB-QTIA",
        "outputId": "adcb834e-bfd0-4faf-e691-9986b7c13532"
      },
      "source": [
        "import csv\r\n",
        "import pandas\r\n",
        "with open('innovators.csv', 'w', newline='') as file:\r\n",
        "    writer = csv.writer(file)\r\n",
        "    writer.writerow([\"index\", \"mail\"])\r\n",
        "    writer.writerow([0, \"Today SoC tutorial class\"])\r\n",
        "    writer.writerow([0, \"New assignment: Providing references of the read‚Ä¶\"])\r\n",
        "    writer.writerow([0, \"Please accept my request to connect\"])\r\n",
        "    writer.writerow([0, \"Stipend issue/inquiry for M.Tech. & Dual Degree Student\"])\r\n",
        "    writer.writerow([0, \"Providing references of the read materials for the C1 component (Unit 1 and 2) - Orientation Camp\"])\r\n",
        "    writer.writerow([0, \"Invitation to Attend Pragma'21 Conference | Aparoksha'21\"])\r\n",
        "    writer.writerow([0, \"Invitation to attend the Opening Ceremony of SheHacks 4.0\"])\r\n",
        "    writer.writerow([0, \"Invitation for Webinar by UBA CELL RGIT on March 13, 2021\"])\r\n",
        "    writer.writerow([0, \"Infosys Certification Powered by InfyTQ: Registrations Open Now!\"])\r\n",
        "    writer.writerow([0, \"Art of Living's Beyond Breath- A Free Workshop for IIITA\"])\r\n",
        "    writer.writerow([0, \"Orientation Camp: C1 - Topics Allotted for Article Writing\"])\r\n",
        "    writer.writerow([0, \"Tomorrow soft computing class is scheduled at 9 am\"])\r\n",
        "    writer.writerow([0, \"join in the 2nd meeting of ICAEEC-2021\"])\r\n",
        "    writer.writerow([0, \"Participate in this equality hackathon and win BIG!\"])\r\n",
        "    writer.writerow([0, \"A talk on Cervical Cancer Awareness on International Womens Day (8th March ,2021)\"])\r\n",
        "    writer.writerow([0, \"Regarding the submission of the PFC assignemnt due on 31 Jan\"])\r\n",
        "    writer.writerow([0, \"Inviting your university students to be part of the prestigious WE program's Cohort 3 - TalentSprint's WE (Women Engineer) program is supported by Google\"])\r\n",
        "    writer.writerow([0, \"Regarding Postman Workshop on Introduction to APIs\"])\r\n",
        "    writer.writerow([0, \"Fellowship opportunities for students as Swachhta Saarthi Fellowship under Waste to Wealth Mission of the Govt. of India\"])\r\n",
        "    writer.writerow([1, \"XXXXXX1217 Unlock your reward now!\"])\r\n",
        "    writer.writerow([1, \"I need new pants? Ending today: ‚Çπ 219 Sports Pants, ‚Çπ 582 Jeans, ‚Çπ 655 Hiking Pants\"])\r\n",
        "    writer.writerow([1, \"Step into the future. üí°Check out these smart home gadgets\"])\r\n",
        "    writer.writerow([1, \"XXXXX1217 We miss your presence. Let's meet soon.\"])\r\n",
        "    writer.writerow([1, \"Opt for contactless toll payment with FASTag\"])\r\n",
        "    writer.writerow([1, \"Hoodie Clearance? ‚Çπ 654 Racing Hoodie, ‚Çπ 436 Anime Hoodie, ‚Çπ 436 Gaming Hoodie, ‚Çπ 436 Combat Hoodie\"])\r\n",
        "    writer.writerow([1, \"Improve GATE Rank with Special Alumni Program. Save Flat Rs 15000 on LIVE Online and Classroom Courses. Check Details Inside\"])\r\n",
        "    writer.writerow([1, \"Your featured recommendations\"])\r\n",
        "    writer.writerow([1, \"IRCTC introduces Jyotirlinga & Statue of Unity Rail Tour package\"])\r\n",
        "    writer.writerow([1, \"See what's NEW in Tops\"])\r\n",
        "    writer.writerow([1, \"Save More! Shave No More\"])\r\n",
        "    writer.writerow([1, \"Take great strides to feeling great in the latest jeans now on sale!\"])\r\n",
        "    writer.writerow([1, \"Pay-day extra earning on the cards! Get 500 Z creditsüí∞ with each referral\"])\r\n",
        "    writer.writerow([1, \"Long Sleeved Shirts, inside!\"])\r\n",
        "    writer.writerow([1, \"IRCTC's Air Packages Ex Mumbai\"])\r\n",
        "    writer.writerow([1, \"The easiest way to book hotels for your next vacation\"])\r\n",
        "    writer.writerow([1, \"XXXXXX1217 Now enjoy instant payment service using UPI\"])\r\n",
        "    writer.writerow([1, \"Get complete control of your cheques with InstaBIZ app\"])\r\n",
        "    writer.writerow([1, \"Which is better, a 40 LPA private job or an 8 LPA government job\"])\r\n",
        "\r\n",
        "df = pandas.read_csv('innovators.csv')\r\n",
        "\r\n",
        "print(df[6:12])\r\n",
        "\r\n"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    index                                               mail\n",
            "6       0  Invitation to attend the Opening Ceremony of S...\n",
            "7       0  Invitation for Webinar by UBA CELL RGIT on Mar...\n",
            "8       0  Infosys Certification Powered by InfyTQ: Regis...\n",
            "9       0  Art of Living's Beyond Breath- A Free Workshop...\n",
            "10      0  Orientation Camp: C1 - Topics Allotted for Art...\n",
            "11      0  Tomorrow soft computing class is scheduled at ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUUcC1BtJukz"
      },
      "source": [
        "##test data is collected from my mail box, here zero index indicates normal messsage and one indicates spam mail "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QfuO3IJcPc4",
        "outputId": "de4b2fe5-0775-4c37-8986-35bbd1fc4232"
      },
      "source": [
        "import csv\r\n",
        "with open('innovator.csv', 'w', newline='') as file:\r\n",
        "    writer = csv.writer(file)\r\n",
        "    writer.writerow([\"index\", \"mail\"])\r\n",
        "    writer.writerow([0, \"New announcement: Class will start at 7:55 pm\"])\r\n",
        "    writer.writerow([0, \"Delegate Invitation:: Export Opportunities for MSMEs, NEDFi House, Guwahati, Assam - 23rd March 2021, 10.30 AM - 01.30 PM\"])\r\n",
        "    writer.writerow([0, \"SCO Secretariat organizing Competition for best article for college students\"])\r\n",
        "    writer.writerow([0, \"C1 Project Evaluation Schedule for Students Under Dr. Maity or Dr. Venkatesan\"])\r\n",
        "    writer.writerow([0, \"Mail your reports and ppt\"])\r\n",
        "    writer.writerow([0, \"PhD Thesis presubmission Seminar of Ms. Shweta\"])\r\n",
        "    writer.writerow([0, \"Help spread the word | 2021 Generation Google Scholarship: for women in computer science\"])\r\n",
        "    writer.writerow([0, \"Invitation for Inaugural session in DST Sponsored FDP Programme on Entrepreneurship Development from March 01st- 12th, 2021 in Online Mode at IIIT Allahabad\"])\r\n",
        "    writer.writerow([0, \"Invitation for Committee Members | E-Summit IIM Lucknow | Enphilia\"])\r\n",
        "    writer.writerow([0, \"IEEE membership discount and free offers\"])\r\n",
        "    writer.writerow([0, \"Exclusive Invite for participants of APROKSHA'21 || CODE KAZE|| 2021 Edition || Placement Opportunity & Cash Rewards || IIIT Allahabad\"])\r\n",
        "    writer.writerow([0, \"HackVerse 2.0 : Workshop on making your First Desktop Application Using Java and MySQL\"])\r\n",
        "    writer.writerow([0, \"Techtonic ‚Äì Innovations in Clean Energy‚Äô - 3rd edition of Energy Challenge from Social Alpha\"])\r\n",
        "    writer.writerow([0, \"Convex Optimization tutorial at 6pm\"])\r\n",
        "    writer.writerow([1, \"Every man needs these accessories. ‚è∞ Shop the sale.\"])\r\n",
        "    writer.writerow([1, \"Your Skin & Hair,üíÜ‚Äç‚ôÄÔ∏è Crave Extra Care\"])\r\n",
        "    writer.writerow([1, \"Where did you get that shirt? 70-90% off all dress shirts and unique polos right now ...üëïüëïüëï\"])\r\n",
        "    writer.writerow([1, \"Say hello to your new V-Necks\"])\r\n",
        "    writer.writerow([1, \"Tricky Tawang Adventure Package\"])\r\n",
        "    writer.writerow([1, \"Slimming and stylish! Don't miss out on pants at 50-80% off!\"])\r\n",
        "    writer.writerow([1, \"Someone just searched for you on Bing\"])\r\n",
        "    writer.writerow([1, \"How are decision trees built? | Zolzaya Luvsandorj in Towards Data Science\"])\r\n",
        "    writer.writerow([1, \"Someone saw Flight Stability And Automa... in an Academia search\"])\r\n",
        "    writer.writerow([1, \"Avail Zero making charges on diamond jewellery this Republic Dayüòç \"])\r\n",
        "    writer.writerow([1, \"Best Of Designs & Irresistible Offers - The Recipe Of A Perfect Sundayüëå\"])\r\n",
        "    writer.writerow([1, \"Still Haven't Decided What To Get Her For Valentine's Day? Tap Tap Tapüíù\"])\r\n",
        "    writer.writerow([1, \"It's Time To Officially Welcome Spring! \"])\r\n",
        "    writer.writerow([1, \"Flight Stability And Automatic Control NELSON was your top paper last week\"])\r\n",
        "    writer.writerow([1, \"Protect your loved ones from future uncertainties! Add nominee to your account\"])\r\n",
        "df_test = pandas.read_csv('innovator.csv')\r\n",
        "\r\n",
        "print(df_test.iloc[5,1])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PhD Thesis presubmission Seminar of Ms. Shweta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGEcrU7RTAgQ"
      },
      "source": [
        "#Navie Bayes classifier - Multi variate Bernoullis Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwusRPJWov3H",
        "outputId": "24a84338-2c4b-4c8b-f87c-21f8264e2115"
      },
      "source": [
        "import pandas\r\n",
        "import re\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def getplanestring (str): \r\n",
        "    pattern = r'[0-9]'\r\n",
        "    str_punctuation = re.sub(r'[^\\w]', ' ', str)\r\n",
        "    str_number = re.sub(pattern, '', str_punctuation)\r\n",
        "    str_number = str_number.lower()\r\n",
        "    return str_number\r\n",
        "\r\n",
        "\r\n",
        "def get_totalwords(df): \r\n",
        "    result_dict =[]\r\n",
        "    for i in range(df.shape[0]): \r\n",
        "        #print(df.iloc[i,1])\r\n",
        "        s= getplanestring(df.iloc[i,1])\r\n",
        "        #print(s)\r\n",
        "        result_instance = s.split()\r\n",
        "        result_dict = [*result_dict, *result_instance]\r\n",
        "    return result_dict\r\n",
        "\r\n",
        "def get_uniquewords(given_list): \r\n",
        "    unique_list = list(dict.fromkeys(given_list))\r\n",
        "    return unique_list\r\n",
        "\r\n",
        "\r\n",
        "def get_model_vect(total_words, unique_words): \r\n",
        "    vect = [1]*len(unique_words)\r\n",
        "    k =0\r\n",
        "    for i in unique_words: \r\n",
        "        c = 0\r\n",
        "        for j in total_words: \r\n",
        "            if (i == j): \r\n",
        "                c = c + 1\r\n",
        "        vect[k] = vect[k] + c\r\n",
        "        k = k +1 \r\n",
        "    for i in range(len(unique_words)): \r\n",
        "        vect[i] = float (vect[i]/len(total_words))\r\n",
        "    return vect     \r\n",
        "\r\n",
        "\r\n",
        "def get_test_vect(test_words, unique_words): \r\n",
        "    vect = [0]*len(unique_words)\r\n",
        "    k =0\r\n",
        "    for i in unique_words:\r\n",
        "        for j in test_words: \r\n",
        "            if (i == j): \r\n",
        "                vect[k] = 1\r\n",
        "        k = k +1 \r\n",
        "    return vect     \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def get_result(vect, vector0, vector1, phi_0, phi_1): \r\n",
        "    p_0 = 1\r\n",
        "    p_1 = 1\r\n",
        "    for i in range(len(vect)): \r\n",
        "        if (vect[i]==1): \r\n",
        "            p_0 = p_0 * vector0[i] * phi_0\r\n",
        "            p_1 = p_1 * vector1[i] * phi_1\r\n",
        "\r\n",
        "    p_class0 = float(p_0/(p_0 + p_1))\r\n",
        "    p_class1 = float(p_1/(p_1 + p_0))\r\n",
        "    if (p_class0 > p_class1): \r\n",
        "        print ('class 0 probability = ' + str(p_class0) +  '   class 1 probability = ' + str(p_class1) + '  predicted calss 0 - normal' )\r\n",
        "        return 0 \r\n",
        "    else : \r\n",
        "        print ('class 0 probability = ' + str(p_class0) +  '   class 1 probability = ' + str(p_class1) + '  predicted calss 1 - spam' )\r\n",
        "        return 1 \r\n",
        "\r\n",
        "\r\n",
        "def accuracy (df_test, vector0, vector1, phi_0, phi_1, unique_words): \r\n",
        "    c =0 \r\n",
        "    result = []\r\n",
        "    for i in range(df_test.shape[0]): \r\n",
        "        get_str = df_test.iloc[i,1]\r\n",
        "        get_plane_str = getplanestring(get_str)\r\n",
        "        test_words = get_plane_str.split()\r\n",
        "        vect = get_test_vect(test_words, unique_words)\r\n",
        "        r = get_result(vect, vector0, vector1, phi_0, phi_1)\r\n",
        "        result.append(r)\r\n",
        "    print(result)\r\n",
        "    for i in range(df_test.shape[0]):\r\n",
        "        if result[i] == df_test.iloc[i,0]: \r\n",
        "            c = c+1 \r\n",
        "    print('final accuracy ratio = ' + str(float( c/ df_test.shape[0])))\r\n",
        "    return float( c/ df_test.shape[0] )\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def multivarient_model (df,index): \r\n",
        "    total_words = get_totalwords(df)\r\n",
        "    unique_words = get_uniquewords(total_words)\r\n",
        "    total_words_class0 = get_totalwords(df[0:index])\r\n",
        "    total_words_class1= get_totalwords(df[index:df.shape[0]])\r\n",
        "    vector_class0 = get_model_vect (total_words_class0, unique_words)\r\n",
        "    vector_class1 = get_model_vect (total_words_class1, unique_words)\r\n",
        "    return vector_class0, vector_class1, unique_words\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "vector0, vector1, unique_words = multivarient_model (df,19)\r\n",
        "print('bag of all word in training set '+ str(unique_words))\r\n",
        "print('probabability of words belonging to class 0 ' + str(vector0))\r\n",
        "print('probabability of words belonging to class 1 ' + str(vector1))\r\n",
        "accuracy (df_test, vector0, vector1, 0.5, 0.5, unique_words)\r\n",
        "\r\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bag of all word in training set ['today', 'soc', 'tutorial', 'class', 'new', 'assignment', 'providing', 'references', 'of', 'the', 'read', 'please', 'accept', 'my', 'request', 'to', 'connect', 'stipend', 'issue', 'inquiry', 'for', 'm', 'tech', 'dual', 'degree', 'student', 'materials', 'c', 'component', 'unit', 'and', 'orientation', 'camp', 'invitation', 'attend', 'pragma', 'conference', 'aparoksha', 'opening', 'ceremony', 'shehacks', 'webinar', 'by', 'uba', 'cell', 'rgit', 'on', 'march', 'infosys', 'certification', 'powered', 'infytq', 'registrations', 'open', 'now', 'art', 'living', 's', 'beyond', 'breath', 'a', 'free', 'workshop', 'iiita', 'topics', 'allotted', 'article', 'writing', 'tomorrow', 'soft', 'computing', 'is', 'scheduled', 'at', 'am', 'join', 'in', 'nd', 'meeting', 'icaeec', 'participate', 'this', 'equality', 'hackathon', 'win', 'big', 'talk', 'cervical', 'cancer', 'awareness', 'international', 'womens', 'day', 'th', 'regarding', 'submission', 'pfc', 'assignemnt', 'due', 'jan', 'inviting', 'your', 'university', 'students', 'be', 'part', 'prestigious', 'we', 'program', 'cohort', 'talentsprint', 'women', 'engineer', 'supported', 'google', 'postman', 'introduction', 'apis', 'fellowship', 'opportunities', 'as', 'swachhta', 'saarthi', 'under', 'waste', 'wealth', 'mission', 'govt', 'india', 'xxxxxx', 'unlock', 'reward', 'i', 'need', 'pants', 'ending', 'sports', 'jeans', 'hiking', 'step', 'into', 'future', 'check', 'out', 'these', 'smart', 'home', 'gadgets', 'xxxxx', 'miss', 'presence', 'let', 'meet', 'soon', 'opt', 'contactless', 'toll', 'payment', 'with', 'fastag', 'hoodie', 'clearance', 'racing', 'anime', 'gaming', 'combat', 'improve', 'gate', 'rank', 'special', 'alumni', 'save', 'flat', 'rs', 'live', 'online', 'classroom', 'courses', 'details', 'inside', 'featured', 'recommendations', 'irctc', 'introduces', 'jyotirlinga', 'statue', 'unity', 'rail', 'tour', 'package', 'see', 'what', 'tops', 'more', 'shave', 'no', 'take', 'great', 'strides', 'feeling', 'latest', 'sale', 'pay', 'extra', 'earning', 'cards', 'get', 'z', 'credits', 'each', 'referral', 'long', 'sleeved', 'shirts', 'air', 'packages', 'ex', 'mumbai', 'easiest', 'way', 'book', 'hotels', 'next', 'vacation', 'enjoy', 'instant', 'service', 'using', 'upi', 'complete', 'control', 'cheques', 'instabiz', 'app', 'which', 'better', 'lpa', 'private', 'job', 'or', 'an', 'government']\n",
            "probabability of words belonging to class 0 [0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.016304347826086956, 0.010869565217391304, 0.010869565217391304, 0.016304347826086956, 0.016304347826086956, 0.05434782608695652, 0.05434782608695652, 0.016304347826086956, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.03804347826086957, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.03804347826086957, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.016304347826086956, 0.010869565217391304, 0.010869565217391304, 0.016304347826086956, 0.016304347826086956, 0.016304347826086956, 0.021739130434782608, 0.016304347826086956, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.021739130434782608, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.03260869565217391, 0.016304347826086956, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.021739130434782608, 0.010869565217391304, 0.010869565217391304, 0.016304347826086956, 0.010869565217391304, 0.016304347826086956, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.016304347826086956, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.016304347826086956, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.016304347826086956, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.016304347826086956, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.016304347826086956, 0.016304347826086956, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.016304347826086956, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.010869565217391304, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652, 0.005434782608695652]\n",
            "probabability of words belonging to class 1 [0.011834319526627219, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.01775147928994083, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.01775147928994083, 0.029585798816568046, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.01775147928994083, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.01775147928994083, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.011834319526627219, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.023668639053254437, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.023668639053254437, 0.005917159763313609, 0.005917159763313609, 0.023668639053254437, 0.005917159763313609, 0.005917159763313609, 0.011834319526627219, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.011834319526627219, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.01775147928994083, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.011834319526627219, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.03550295857988166, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.011834319526627219, 0.011834319526627219, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.005917159763313609, 0.01775147928994083, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.023668639053254437, 0.011834319526627219, 0.011834319526627219, 0.01775147928994083, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.01775147928994083, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.01775147928994083, 0.029585798816568046, 0.011834319526627219, 0.03550295857988166, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.01775147928994083, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.01775147928994083, 0.011834319526627219, 0.011834319526627219, 0.01775147928994083, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.01775147928994083, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.01775147928994083, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.01775147928994083, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219, 0.01775147928994083, 0.011834319526627219, 0.01775147928994083, 0.011834319526627219, 0.011834319526627219, 0.011834319526627219]\n",
            "class 0 probability = 0.7560571944578673   class 1 probability = 0.24394280554213266  predicted calss 0 - normal\n",
            "class 0 probability = 0.9865244829743856   class 1 probability = 0.013475517025614345  predicted calss 0 - normal\n",
            "class 0 probability = 0.9155949007673345   class 1 probability = 0.0844050992326654  predicted calss 0 - normal\n",
            "class 0 probability = 0.9320957692086632   class 1 probability = 0.06790423079133691  predicted calss 0 - normal\n",
            "class 0 probability = 0.2966667705379494   class 1 probability = 0.7033332294620506  predicted calss 1 - spam\n",
            "class 0 probability = 0.7537912578055308   class 1 probability = 0.24620874219446923  predicted calss 0 - normal\n",
            "class 0 probability = 0.9242507025815192   class 1 probability = 0.07574929741848076  predicted calss 0 - normal\n",
            "class 0 probability = 0.977034311150426   class 1 probability = 0.022965688849573864  predicted calss 0 - normal\n",
            "class 0 probability = 0.8873064410901876   class 1 probability = 0.11269355890981231  predicted calss 0 - normal\n",
            "class 0 probability = 0.7167786245493102   class 1 probability = 0.28322137545068976  predicted calss 0 - normal\n",
            "class 0 probability = 0.8677485075786446   class 1 probability = 0.13225149242135545  predicted calss 0 - normal\n",
            "class 0 probability = 0.4237489641252561   class 1 probability = 0.5762510358747439  predicted calss 1 - spam\n",
            "class 0 probability = 0.7376710453589821   class 1 probability = 0.2623289546410178  predicted calss 0 - normal\n",
            "class 0 probability = 0.7713977042538825   class 1 probability = 0.2286022957461175  predicted calss 0 - normal\n",
            "class 0 probability = 0.2792352250402743   class 1 probability = 0.7207647749597257  predicted calss 1 - spam\n",
            "class 0 probability = 0.12326875186126708   class 1 probability = 0.8767312481387329  predicted calss 1 - spam\n",
            "class 0 probability = 0.08169102897085022   class 1 probability = 0.9183089710291498  predicted calss 1 - spam\n",
            "class 0 probability = 0.286613104679372   class 1 probability = 0.7133868953206279  predicted calss 1 - spam\n",
            "class 0 probability = 0.3147113594040968   class 1 probability = 0.6852886405959031  predicted calss 1 - spam\n",
            "class 0 probability = 0.14445958155993235   class 1 probability = 0.8555404184400677  predicted calss 1 - spam\n",
            "class 0 probability = 0.7470024921629509   class 1 probability = 0.2529975078370491  predicted calss 0 - normal\n",
            "class 0 probability = 0.47875354107648727   class 1 probability = 0.5212464589235128  predicted calss 1 - spam\n",
            "class 0 probability = 0.3675380522017076   class 1 probability = 0.6324619477982925  predicted calss 1 - spam\n",
            "class 0 probability = 0.6992020881189802   class 1 probability = 0.3007979118810198  predicted calss 0 - normal\n",
            "class 0 probability = 0.8856921279864208   class 1 probability = 0.11430787201357917  predicted calss 0 - normal\n",
            "class 0 probability = 0.35265571595969697   class 1 probability = 0.647344284040303  predicted calss 1 - spam\n",
            "class 0 probability = 0.6631187913564073   class 1 probability = 0.3368812086435928  predicted calss 0 - normal\n",
            "class 0 probability = 0.16227390815040935   class 1 probability = 0.8377260918495907  predicted calss 1 - spam\n",
            "class 0 probability = 0.2315512329516837   class 1 probability = 0.7684487670483164  predicted calss 1 - spam\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1]\n",
            "final accuracy ratio = 0.7931034482758621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7931034482758621"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBIzI-w9rx89"
      },
      "source": [
        "#Navie Bayes classifier - Multinomial Event Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45mugoTGrydC",
        "outputId": "25ec5a28-f857-4dc3-d1aa-999825936466"
      },
      "source": [
        "from functools import reduce \r\n",
        "\r\n",
        "total_words_class0 = get_totalwords(df[0:18])\r\n",
        "total_words_class1=  get_totalwords(df[18:df.shape[0]])\r\n",
        "\r\n",
        "def feature_vector (test_sentence,df): \r\n",
        "    total_words_class0 = get_totalwords(df[0:18])\r\n",
        "    total_words_class1=  get_totalwords(df[18:df.shape[0]])\r\n",
        "    plane_string = getplanestring (test_sentence)\r\n",
        "    result_instance = plane_string.split()\r\n",
        "    unique_list = list(dict.fromkeys(result_instance))\r\n",
        "    #print(unique_list)\r\n",
        "    feature_vect0 = []\r\n",
        "    feature_vect1 = []\r\n",
        "    for i in unique_list: \r\n",
        "        c = 1\r\n",
        "        for j in total_words_class0: \r\n",
        "            if i == j: \r\n",
        "                c = c+1 \r\n",
        "        feature_vect0.append(c)\r\n",
        "    for i in unique_list: \r\n",
        "        c = 1\r\n",
        "        for j in total_words_class1: \r\n",
        "            if i == j: \r\n",
        "                c = c+1 \r\n",
        "        feature_vect1.append(c)\r\n",
        "    for i in range(len(unique_list)): \r\n",
        "        feature_vect1[i] = float (feature_vect1[i]/len(total_words_class1))\r\n",
        "\r\n",
        "    for i in range(len(unique_list)): \r\n",
        "        feature_vect0[i] = float (feature_vect0[i]/len(total_words_class0))\r\n",
        "    #print(feature_vect0)\r\n",
        "    #print(feature_vect1)\r\n",
        "\r\n",
        "    return feature_vect0, feature_vect1\r\n",
        "\r\n",
        "\r\n",
        "def result(test_sentence,df, phi0, phi1): \r\n",
        "    feature0, feature1 = feature_vector (test_sentence,df)\r\n",
        "    p_0 = reduce(lambda a,b : a*b , feature0)\r\n",
        "    p_1 = reduce(lambda a,b : a*b , feature1)\r\n",
        "    probability0 = p_0 * phi0\r\n",
        "    probability1 = p_1 * phi1\r\n",
        "    #print('probability of class 0 = ' + str(probability0) + '  probability of class 1 = ' + str(probability1))\r\n",
        "    if probability0 > probability1 :\r\n",
        "        return 0 \r\n",
        "    else:\r\n",
        "        return 1\r\n",
        "\r\n",
        "\r\n",
        "def accuracy_multinomial (df_test, df, phi0, phi1): \r\n",
        "    result_vect = []\r\n",
        "    for i in range(df_test.shape[0]): \r\n",
        "        r = result(df_test.iloc[i,1], df, phi0, phi1)\r\n",
        "        result_vect.append(r)\r\n",
        "    print(result_vect)\r\n",
        "    c =0\r\n",
        "    for i in range(df_test.shape[0]):\r\n",
        "        if result_vect[i] == df_test.iloc[i,0]: \r\n",
        "            c = c+1 \r\n",
        "    print('final accuracy ratio = ' + str(float( c/ df_test.shape[0])))\r\n",
        "    return float( c/ df_test.shape[0] )\r\n",
        "\r\n",
        "accuracy_multinomial(df_test, df, 0.5, 0.5)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "final accuracy ratio = 0.6551724137931034\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6551724137931034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYJYuo6MKiJJ"
      },
      "source": [
        "#Gaussian Discriminant Analysis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hBRaWOZN91e"
      },
      "source": [
        "## converting data to matrix form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-XgC8S9YKtPM",
        "outputId": "3102e197-dc65-409e-f099-88651cc64e6d"
      },
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "def get_test_vect1(test_words, unique_words): \r\n",
        "    vect = [1]*len(unique_words)\r\n",
        "    k =0\r\n",
        "    for i in unique_words:\r\n",
        "        c =1\r\n",
        "        for j in test_words: \r\n",
        "            if (i == j): \r\n",
        "                c = c+1\r\n",
        "                vect[k] = c\r\n",
        "        k = k +1 \r\n",
        "    return vect     \r\n",
        "\r\n",
        "\r\n",
        "def get_train_x (df): \r\n",
        "    words = get_totalwords(df)\r\n",
        "    unique_words = get_uniquewords(words)\r\n",
        "    print(words)\r\n",
        "    #print(unique_words)\r\n",
        "    d = np.zeros((1, len(unique_words)))\r\n",
        "    #print(d)\r\n",
        "    for i in range(df.shape[0]):\r\n",
        "        get_str = df.iloc[i,1]\r\n",
        "        get_plane_str = getplanestring(get_str)\r\n",
        "        test_words = get_plane_str.split()\r\n",
        "        print(test_words)\r\n",
        "        vect = get_test_vect1(test_words, unique_words)\r\n",
        "        print(vect)\r\n",
        "        d = np.vstack((d,vect))\r\n",
        "    d = np.delete(d, (0), axis=0)\r\n",
        "    return d\r\n",
        "\r\n",
        "\r\n",
        "def get_test_x (df, df_test): \r\n",
        "    words = get_totalwords(df)\r\n",
        "    unique_words = get_uniquewords(words)\r\n",
        "    #print(unique_words)\r\n",
        "    d = np.zeros((1, len(unique_words)))\r\n",
        "    #print(d)\r\n",
        "    for i in range(df_test.shape[0]):\r\n",
        "        get_str = df_test.iloc[i,1]\r\n",
        "        get_plane_str = getplanestring(get_str)\r\n",
        "        test_words = get_plane_str.split()\r\n",
        "        vect = get_test_vect1(test_words, unique_words)\r\n",
        "        #print(vect)\r\n",
        "        d = np.vstack((d,vect))\r\n",
        "    d = np.delete(d, (0), axis=0)\r\n",
        "    return d\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def get_train_y(df):\r\n",
        "    d = np.zeros((1, 1))\r\n",
        "    print(d)\r\n",
        "    for i in range(df.shape[0]):\r\n",
        "        v = []\r\n",
        "        v.append(df.iloc[i,0])\r\n",
        "        d = np.vstack((d,v))\r\n",
        "    d = np.delete(d, (0), axis=0)\r\n",
        "    return d\r\n",
        "\r\n",
        "\r\n",
        "X = get_train_x (df)\r\n",
        "print(X)\r\n",
        "Y = get_train_y(df)\r\n",
        "#print(Y)\r\n",
        "\r\n",
        "\r\n",
        "'''\r\n",
        "X_test = get_test_x(df, df_test)\r\n",
        "print(X_test)\r\n",
        "Y_test= get_train_y(df_test)\r\n",
        "print(Y_test)\r\n",
        "\r\n",
        "\r\n",
        "for row in X_test: \r\n",
        "  print(row)\r\n",
        "'''\r\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['today', 'soc', 'tutorial', 'class', 'new', 'assignment', 'providing', 'references', 'of', 'the', 'read', 'please', 'accept', 'my', 'request', 'to', 'connect', 'stipend', 'issue', 'inquiry', 'for', 'm', 'tech', 'dual', 'degree', 'student', 'providing', 'references', 'of', 'the', 'read', 'materials', 'for', 'the', 'c', 'component', 'unit', 'and', 'orientation', 'camp', 'invitation', 'to', 'attend', 'pragma', 'conference', 'aparoksha', 'invitation', 'to', 'attend', 'the', 'opening', 'ceremony', 'of', 'shehacks', 'invitation', 'for', 'webinar', 'by', 'uba', 'cell', 'rgit', 'on', 'march', 'infosys', 'certification', 'powered', 'by', 'infytq', 'registrations', 'open', 'now', 'art', 'of', 'living', 's', 'beyond', 'breath', 'a', 'free', 'workshop', 'for', 'iiita', 'orientation', 'camp', 'c', 'topics', 'allotted', 'for', 'article', 'writing', 'tomorrow', 'soft', 'computing', 'class', 'is', 'scheduled', 'at', 'am', 'join', 'in', 'the', 'nd', 'meeting', 'of', 'icaeec', 'participate', 'in', 'this', 'equality', 'hackathon', 'and', 'win', 'big', 'a', 'talk', 'on', 'cervical', 'cancer', 'awareness', 'on', 'international', 'womens', 'day', 'th', 'march', 'regarding', 'the', 'submission', 'of', 'the', 'pfc', 'assignemnt', 'due', 'on', 'jan', 'inviting', 'your', 'university', 'students', 'to', 'be', 'part', 'of', 'the', 'prestigious', 'we', 'program', 's', 'cohort', 'talentsprint', 's', 'we', 'women', 'engineer', 'program', 'is', 'supported', 'by', 'google', 'regarding', 'postman', 'workshop', 'on', 'introduction', 'to', 'apis', 'fellowship', 'opportunities', 'for', 'students', 'as', 'swachhta', 'saarthi', 'fellowship', 'under', 'waste', 'to', 'wealth', 'mission', 'of', 'the', 'govt', 'of', 'india', 'xxxxxx', 'unlock', 'your', 'reward', 'now', 'i', 'need', 'new', 'pants', 'ending', 'today', 'sports', 'pants', 'jeans', 'hiking', 'pants', 'step', 'into', 'the', 'future', 'check', 'out', 'these', 'smart', 'home', 'gadgets', 'xxxxx', 'we', 'miss', 'your', 'presence', 'let', 's', 'meet', 'soon', 'opt', 'for', 'contactless', 'toll', 'payment', 'with', 'fastag', 'hoodie', 'clearance', 'racing', 'hoodie', 'anime', 'hoodie', 'gaming', 'hoodie', 'combat', 'hoodie', 'improve', 'gate', 'rank', 'with', 'special', 'alumni', 'program', 'save', 'flat', 'rs', 'on', 'live', 'online', 'and', 'classroom', 'courses', 'check', 'details', 'inside', 'your', 'featured', 'recommendations', 'irctc', 'introduces', 'jyotirlinga', 'statue', 'of', 'unity', 'rail', 'tour', 'package', 'see', 'what', 's', 'new', 'in', 'tops', 'save', 'more', 'shave', 'no', 'more', 'take', 'great', 'strides', 'to', 'feeling', 'great', 'in', 'the', 'latest', 'jeans', 'now', 'on', 'sale', 'pay', 'day', 'extra', 'earning', 'on', 'the', 'cards', 'get', 'z', 'credits', 'with', 'each', 'referral', 'long', 'sleeved', 'shirts', 'inside', 'irctc', 's', 'air', 'packages', 'ex', 'mumbai', 'the', 'easiest', 'way', 'to', 'book', 'hotels', 'for', 'your', 'next', 'vacation', 'xxxxxx', 'now', 'enjoy', 'instant', 'payment', 'service', 'using', 'upi', 'get', 'complete', 'control', 'of', 'your', 'cheques', 'with', 'instabiz', 'app', 'which', 'is', 'better', 'a', 'lpa', 'private', 'job', 'or', 'an', 'lpa', 'government', 'job']\n",
            "['today', 'soc', 'tutorial', 'class']\n",
            "[2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['new', 'assignment', 'providing', 'references', 'of', 'the', 'read']\n",
            "[1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['please', 'accept', 'my', 'request', 'to', 'connect']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['stipend', 'issue', 'inquiry', 'for', 'm', 'tech', 'dual', 'degree', 'student']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['providing', 'references', 'of', 'the', 'read', 'materials', 'for', 'the', 'c', 'component', 'unit', 'and', 'orientation', 'camp']\n",
            "[1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['invitation', 'to', 'attend', 'pragma', 'conference', 'aparoksha']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['invitation', 'to', 'attend', 'the', 'opening', 'ceremony', 'of', 'shehacks']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['invitation', 'for', 'webinar', 'by', 'uba', 'cell', 'rgit', 'on', 'march']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['infosys', 'certification', 'powered', 'by', 'infytq', 'registrations', 'open', 'now']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['art', 'of', 'living', 's', 'beyond', 'breath', 'a', 'free', 'workshop', 'for', 'iiita']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['orientation', 'camp', 'c', 'topics', 'allotted', 'for', 'article', 'writing']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['tomorrow', 'soft', 'computing', 'class', 'is', 'scheduled', 'at', 'am']\n",
            "[1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['join', 'in', 'the', 'nd', 'meeting', 'of', 'icaeec']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['participate', 'in', 'this', 'equality', 'hackathon', 'and', 'win', 'big']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['a', 'talk', 'on', 'cervical', 'cancer', 'awareness', 'on', 'international', 'womens', 'day', 'th', 'march']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['regarding', 'the', 'submission', 'of', 'the', 'pfc', 'assignemnt', 'due', 'on', 'jan']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['inviting', 'your', 'university', 'students', 'to', 'be', 'part', 'of', 'the', 'prestigious', 'we', 'program', 's', 'cohort', 'talentsprint', 's', 'we', 'women', 'engineer', 'program', 'is', 'supported', 'by', 'google']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['regarding', 'postman', 'workshop', 'on', 'introduction', 'to', 'apis']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['fellowship', 'opportunities', 'for', 'students', 'as', 'swachhta', 'saarthi', 'fellowship', 'under', 'waste', 'to', 'wealth', 'mission', 'of', 'the', 'govt', 'of', 'india']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['xxxxxx', 'unlock', 'your', 'reward', 'now']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['i', 'need', 'new', 'pants', 'ending', 'today', 'sports', 'pants', 'jeans', 'hiking', 'pants']\n",
            "[2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 4, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['step', 'into', 'the', 'future', 'check', 'out', 'these', 'smart', 'home', 'gadgets']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['xxxxx', 'we', 'miss', 'your', 'presence', 'let', 's', 'meet', 'soon']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['opt', 'for', 'contactless', 'toll', 'payment', 'with', 'fastag']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['hoodie', 'clearance', 'racing', 'hoodie', 'anime', 'hoodie', 'gaming', 'hoodie', 'combat', 'hoodie']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['improve', 'gate', 'rank', 'with', 'special', 'alumni', 'program', 'save', 'flat', 'rs', 'on', 'live', 'online', 'and', 'classroom', 'courses', 'check', 'details', 'inside']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['your', 'featured', 'recommendations']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['irctc', 'introduces', 'jyotirlinga', 'statue', 'of', 'unity', 'rail', 'tour', 'package']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['see', 'what', 's', 'new', 'in', 'tops']\n",
            "[1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['save', 'more', 'shave', 'no', 'more']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['take', 'great', 'strides', 'to', 'feeling', 'great', 'in', 'the', 'latest', 'jeans', 'now', 'on', 'sale']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['pay', 'day', 'extra', 'earning', 'on', 'the', 'cards', 'get', 'z', 'credits', 'with', 'each', 'referral']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['long', 'sleeved', 'shirts', 'inside']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['irctc', 's', 'air', 'packages', 'ex', 'mumbai']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['the', 'easiest', 'way', 'to', 'book', 'hotels', 'for', 'your', 'next', 'vacation']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['xxxxxx', 'now', 'enjoy', 'instant', 'payment', 'service', 'using', 'upi']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['get', 'complete', 'control', 'of', 'your', 'cheques', 'with', 'instabiz', 'app']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "['which', 'is', 'better', 'a', 'lpa', 'private', 'job', 'or', 'an', 'lpa', 'government', 'job']\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 2, 3, 2, 2, 2]\n",
            "[[2. 2. 2. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " ...\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 1. 1. 1.]\n",
            " [1. 1. 1. ... 2. 2. 2.]]\n",
            "[[0.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nX_test = get_test_x(df, df_test)\\nprint(X_test)\\nY_test= get_train_y(df_test)\\nprint(Y_test)\\n\\n\\nfor row in X_test: \\n  print(row)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msUWW4LNY1iQ"
      },
      "source": [
        "##calculate mu "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoVVPrglY9Ns",
        "outputId": "fc0bfcd6-ef85-4ef5-e1e6-0f3ed0e322ab"
      },
      "source": [
        "def mui(X, Y, index): \r\n",
        "    m = len(Y)\r\n",
        "    n = X.shape[1]\r\n",
        "    sum = [0]*n\r\n",
        "    c =0\r\n",
        "\r\n",
        "    for i in range(m): \r\n",
        "        if Y[i] == index: \r\n",
        "            sum = sum + X[i]\r\n",
        "            c = c+1\r\n",
        "    #print(c)\r\n",
        "    return sum/c\r\n",
        "\r\n",
        "print(mui(X,Y, 0))\r\n",
        "print(mui(X,Y, 1))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.05263158 1.05263158 1.05263158 1.10526316 1.05263158 1.05263158\n",
            " 1.10526316 1.10526316 1.47368421 1.47368421 1.10526316 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.31578947 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.31578947 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.10526316 1.05263158 1.05263158\n",
            " 1.10526316 1.10526316 1.10526316 1.15789474 1.10526316 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.15789474 1.05263158 1.05263158 1.05263158 1.26315789 1.10526316\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.15789474 1.05263158 1.05263158\n",
            " 1.10526316 1.05263158 1.10526316 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.10526316\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.10526316 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.10526316 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.10526316 1.05263158 1.05263158 1.05263158 1.10526316\n",
            " 1.10526316 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.10526316 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.        ]\n",
            "[1.05263158 1.         1.         1.         1.10526316 1.\n",
            " 1.         1.         1.10526316 1.21052632 1.         1.\n",
            " 1.         1.         1.         1.10526316 1.         1.\n",
            " 1.         1.         1.10526316 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.05263158 1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.15789474 1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.15789474 1.         1.         1.15789474 1.         1.\n",
            " 1.05263158 1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.05263158\n",
            " 1.         1.         1.         1.         1.10526316 1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.05263158 1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.26315789\n",
            " 1.         1.         1.         1.         1.         1.05263158\n",
            " 1.05263158 1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.         1.         1.\n",
            " 1.         1.         1.         1.10526316 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.15789474 1.05263158 1.05263158 1.10526316\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.10526316 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.10526316 1.21052632 1.05263158 1.26315789 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.10526316 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.10526316\n",
            " 1.05263158 1.05263158 1.10526316 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.10526316 1.05263158 1.05263158 1.05263158 1.10526316\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.10526316 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158 1.05263158\n",
            " 1.05263158 1.05263158 1.10526316 1.05263158 1.10526316 1.05263158\n",
            " 1.05263158 1.05263158]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0c78LzDZFM5"
      },
      "source": [
        "##calculate sigma "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "PFYAqK7cZGVK",
        "outputId": "1b76764e-795a-4ca0-ac28-9a03b150449e"
      },
      "source": [
        "import random\r\n",
        "\r\n",
        "def sigma (X,Y, mu0, mu1): \r\n",
        "    m = len(Y)\r\n",
        "    n = X.shape[1]\r\n",
        "    sigma = [[0]*n]*n\r\n",
        "    for i in range(m): \r\n",
        " \r\n",
        "        if Y[i] == 0: \r\n",
        "            temp1 = np.array([X[i]-mu0])\r\n",
        "            temp2 = np.transpose(temp1)\r\n",
        "            result = np.dot(temp2, temp1)\r\n",
        "            sigma = sigma + result\r\n",
        "        if Y[i] == 1: \r\n",
        "            temp1 = np.array([X[i]-mu1])\r\n",
        "            temp2 = np.transpose(temp1)\r\n",
        "            result = np.dot(temp2, temp1)\r\n",
        "            sigma = sigma + result\r\n",
        "    return sigma \r\n",
        "\r\n",
        "mu0 = mui(X,Y,0)\r\n",
        "mu1 = mui(X,Y,1)\r\n",
        "sigmaa= sigma(X,Y,mu0,mu1)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "'''\r\n",
        "for i in range(sigmaa.shape[0]): \r\n",
        "    c = random.random()\r\n",
        "    print(c)\r\n",
        "    k = random.randrange(0, sigmaa.shape[0])\r\n",
        "    sigmaa[i][k] = c\r\n",
        "\r\n",
        "for i in range(sigmaa.shape[0]): \r\n",
        "    for j in range(i+1, sigmaa.shape[0]): \r\n",
        "        c = 1\r\n",
        "        for k in range(sigmaa.shape[1]):\r\n",
        "            if (sigmaa[i][k] != sigmaa[j][k]):\r\n",
        "                c = 0\r\n",
        "        if c ==1: \r\n",
        "            print(str(i) + ' equals ' + str(j))\r\n",
        "\r\n",
        "sigma_inv = np.linalg.pinv(sigmaa)\r\n",
        "'''"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nfor i in range(sigmaa.shape[0]): \\n    c = random.random()\\n    print(c)\\n    k = random.randrange(0, sigmaa.shape[0])\\n    sigmaa[i][k] = c\\n\\nfor i in range(sigmaa.shape[0]): \\n    for j in range(i+1, sigmaa.shape[0]): \\n        c = 1\\n        for k in range(sigmaa.shape[1]):\\n            if (sigmaa[i][k] != sigmaa[j][k]):\\n                c = 0\\n        if c ==1: \\n            print(str(i) + ' equals ' + str(j))\\n\\nsigma_inv = np.linalg.pinv(sigmaa)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_mYrta1ZKwp"
      },
      "source": [
        "## predicting values \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "142hF-4dZOfN",
        "outputId": "d408abc2-cf71-46da-d2f1-3bd595431ba3"
      },
      "source": [
        "import math\r\n",
        "\r\n",
        "def calculate_px_py(x, mu, sigma):\r\n",
        "  n = 1\r\n",
        "  pi = 3.14\r\n",
        "  dim = len(mu)\r\n",
        "  \r\n",
        "\r\n",
        "  temp1 = np.array([x-mu])\r\n",
        "  temp2 = np.transpose(temp1)\r\n",
        "\r\n",
        "  val =  pow(2*pi,dim/2)\r\n",
        "  sigma_det = np.sqrt(np.linalg.det(sigma))\r\n",
        "  sigma_det = 0.1\r\n",
        "  val = val * sigma_det\r\n",
        "  val = 1/val\r\n",
        "  \r\n",
        "  sigma_inv = np.linalg.pinv(sigma)\r\n",
        "  multi = np.dot(temp1, sigma_inv)\r\n",
        "  multi = np.dot(multi, temp2)\r\n",
        "  return val *  math.exp(-0.5*multi[0][0])\r\n",
        "\r\n",
        "\r\n",
        "mu0 = mui(X,Y,0)\r\n",
        "mu1 = mui(X,Y,1)\r\n",
        "sigmaa = sigma(X,Y,mu0,mu1)\r\n",
        "print('done')\r\n",
        "print(calculate_px_py(X[0], mu0, sigmaa))\r\n"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n",
            "1.7424674297567923e-96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX2cY2WOZShs"
      },
      "source": [
        "## getting accuracy ratio for given 2 features in microchip data set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVWQQTyGZWZt",
        "outputId": "e5415d7d-5fa6-4909-f0d6-a4e0bfed4e22"
      },
      "source": [
        "x1 = X[9]\r\n",
        "print(Y[9])\r\n",
        "\r\n",
        "mu0 = mui(X,Y,0)\r\n",
        "mu1 = mui(X,Y,1)\r\n",
        "sigmaa = sigma(X,Y,mu0,mu1)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def testing (xtest, ytest, mu0, mu1, sigma):\r\n",
        "\r\n",
        "    l = len(xtest)\r\n",
        "    count = 0 \r\n",
        "  \r\n",
        "    for i in range(l):\r\n",
        "        px0_0 = calculate_px_py(xtest[i], mu0, sigma) * 0.5\r\n",
        "        px0_1 = calculate_px_py(xtest[i], mu1, sigma) * 0.5\r\n",
        "        if px0_0 > px0_1: \r\n",
        "            predicted = 0\r\n",
        "        else: \r\n",
        "            predicted = 1\r\n",
        "          \r\n",
        "        print('probability of class 0 = ' + str(px0_0) + ', probability of class 1 = ' + str(px0_1) + ', actual class = '+ str(ytest[i]) , 'predicted class = ' + str(predicted))\r\n",
        "        if predicted == ytest[i]:  \r\n",
        "            count = count + 1\r\n",
        "    #print ('accuracy is = ' + str(count/l))\r\n",
        "    return count/l\r\n",
        "\r\n",
        "testing(X_test, Y_test, mu0, mu1, sigmaa)\r\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.]\n",
            "probability of class 0 = 1.2770117637674466e-96, probability of class 1 = 1.3024689640999382e-96, actual class = [0.] predicted class = 1\n",
            "probability of class 0 = 1.3145327871404287e-96, probability of class 1 = 1.2760099271319886e-96, actual class = [0.] predicted class = 0\n",
            "probability of class 0 = 1.274844194922168e-96, probability of class 1 = 1.2625755820688695e-96, actual class = [0.] predicted class = 0\n",
            "probability of class 0 = 1.3438104586585772e-96, probability of class 1 = 1.3217188107412147e-96, actual class = [0.] predicted class = 0\n",
            "probability of class 0 = 1.313143671336952e-96, probability of class 1 = 1.31025753523382e-96, actual class = [0.] predicted class = 0\n",
            "probability of class 0 = 1.3608275578692112e-96, probability of class 1 = 1.3653290690319998e-96, actual class = [0.] predicted class = 1\n",
            "probability of class 0 = 1.335011722416151e-96, probability of class 1 = 1.3059721534206147e-96, actual class = [0.] predicted class = 0\n",
            "probability of class 0 = 1.1801099915664898e-96, probability of class 1 = 1.133886585415772e-96, actual class = [0.] predicted class = 0\n",
            "probability of class 0 = 1.3471182968496201e-96, probability of class 1 = 1.3284659831467584e-96, actual class = [0.] predicted class = 0\n",
            "probability of class 0 = 1.3566590874137422e-96, probability of class 1 = 1.3504880002358473e-96, actual class = [0.] predicted class = 0\n",
            "probability of class 0 = 1.3642075821388209e-96, probability of class 1 = 1.3518196771610704e-96, actual class = [0.] predicted class = 0\n",
            "probability of class 0 = 1.2731316280125844e-96, probability of class 1 = 1.2580446874064812e-96, actual class = [0.] predicted class = 0\n",
            "probability of class 0 = 1.3361061282129858e-96, probability of class 1 = 1.3353461202125158e-96, actual class = [0.] predicted class = 0\n",
            "probability of class 0 = 1.3263642766354855e-96, probability of class 1 = 1.3458390132982256e-96, actual class = [0.] predicted class = 1\n",
            "probability of class 0 = 1.354343738347761e-96, probability of class 1 = 1.3578095635375755e-96, actual class = [1.] predicted class = 1\n",
            "probability of class 0 = 1.3132132516142434e-96, probability of class 1 = 1.3311629119417674e-96, actual class = [1.] predicted class = 1\n",
            "probability of class 0 = 1.2939198826993025e-96, probability of class 1 = 1.2949030024608906e-96, actual class = [1.] predicted class = 1\n",
            "probability of class 0 = 1.2696197148287554e-96, probability of class 1 = 1.2888339737782971e-96, actual class = [1.] predicted class = 1\n",
            "probability of class 0 = 1.3596996252243907e-96, probability of class 1 = 1.3721324497534704e-96, actual class = [1.] predicted class = 1\n",
            "probability of class 0 = 1.2968417245577204e-96, probability of class 1 = 1.2925272195336015e-96, actual class = [1.] predicted class = 0\n",
            "probability of class 0 = 1.3590583032512446e-96, probability of class 1 = 1.3467131296407227e-96, actual class = [1.] predicted class = 0\n",
            "probability of class 0 = 1.3429893836724554e-96, probability of class 1 = 1.350255007221787e-96, actual class = [1.] predicted class = 1\n",
            "probability of class 0 = 1.3240585079599387e-96, probability of class 1 = 1.3178844905712185e-96, actual class = [1.] predicted class = 0\n",
            "probability of class 0 = 1.340376995463069e-96, probability of class 1 = 1.3474916619708117e-96, actual class = [1.] predicted class = 1\n",
            "probability of class 0 = 1.2809708901617794e-96, probability of class 1 = 1.2589831701542363e-96, actual class = [1.] predicted class = 0\n",
            "probability of class 0 = 1.268979016812874e-96, probability of class 1 = 1.2380795457884168e-96, actual class = [1.] predicted class = 0\n",
            "probability of class 0 = 1.3425250525688327e-96, probability of class 1 = 1.3363039401523847e-96, actual class = [1.] predicted class = 0\n",
            "probability of class 0 = 1.302195978688713e-96, probability of class 1 = 1.3042554385506714e-96, actual class = [1.] predicted class = 1\n",
            "probability of class 0 = 1.1972197754038077e-96, probability of class 1 = 1.2066922415298546e-96, actual class = [1.] predicted class = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6896551724137931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMwOPLenyd-J"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}